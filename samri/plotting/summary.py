#!/usr/bin/env python
import os

from nilearn.input_data import NiftiLabelsMasker, NiftiMapsMasker
from nipype.interfaces.io import DataFinder
import nibabel as nib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from nilearn.input_data import NiftiMasker

import matplotlib.gridspec as gridspec

sns.set_style("white", {'legend.frameon': True})
plt.style.use('ggplot')


import statsmodels.api as sm
import statsmodels.formula.api as smf
try:
	import maps, timeseries
except ImportError:
	from ..plotting import maps, timeseries

from statsmodels.sandbox.stats.multicomp import multipletests

from joblib import Parallel, delayed
import multiprocessing as mp

import inspect

from itertools import product
from copy import deepcopy

qualitative_colorset = ["#000000", "#E69F00", "#56B4E9", "#009E73","#F0E442", "#0072B2", "#D55E00", "#CC79A7"]

try: FileNotFoundError
except NameError:
	class FileNotFoundError(OSError):
		pass

def add_roi_data(l1_dir,subject,session,masker):
	session_participant_format = "/home/chymera/NIdata/ofM.dr/l1/{0}/sub-{1}/ses-{2}/sub-{1}_ses-{2}_trial-7_EPI_CBV_tstat.nii.gz"
	subject_data={}
	try:
		session_participant_file = session_participant_format.format(l1_dir,subject,session)
		img = nib.load(session_participant_file)
		img = masker.fit_transform(img)
		img = img.flatten()
		mean = np.nanmean(img)
	except (FileNotFoundError, nib.py3k.FileNotFoundError):
		return pd.DataFrame({}), pd.DataFrame({})
	else:
		subject_data["session"]=session
		subject_data["subject"]=subject
		for i in img:
			voxel_data = deepcopy(subject_data)
			voxel_data["t"]=i
			vdf = pd.DataFrame(voxel_data, index=[None])
		subject_data["t"]=mean
		sdf = pd.DataFrame(subject_data, index=[None])
		return sdf, vdf

def roi_per_session(l1_dir, subjects, sessions,
	legend_loc="best",
	roi="f_dr",
	figure="per-participant",
	tabref="tab",
	xy_label=[],
	obfuscate=False,
	matplotlibrc=False,
	color="#E69F00"
	):

	if matplotlibrc:
		matplotlibrc.main()

	roi_path = "/home/chymera/NIdata/templates/roi/{}_chr.nii.gz".format(roi)
	masker = NiftiMasker(mask_img=roi_path)

	iter_product = product(subjects, sessions)
	iter_subjects = []
	iter_sessions = []
	for i in iter_product:
		iter_subjects.append(i[0])
		iter_sessions.append(i[1])
	iter_len = len(iter_sessions)
	n_jobs = mp.cpu_count()-2
	roi_data = Parallel(n_jobs=n_jobs, verbose=0, backend="threading")(map(delayed(add_roi_data),
		[l1_dir]*iter_len,
		iter_subjects,
		iter_sessions,
		[masker]*iter_len,
		))
	subject_dfs, voxel_dfs = zip(*roi_data)
	subjectdf = pd.concat(subject_dfs)
	voxeldf = pd.concat(voxel_dfs)

	if obfuscate:
		obf_session = {"ofM":"_pre","ofM_aF":"t1","ofM_cF1":"t2","ofM_cF2":"t3","ofM_pF":"post"}
		subjectdf = subjectdf.replace({"session": obf_session})
		subjectdf.to_csv("~/MixedLM_data.csv")

	model = smf.mixedlm("t ~ session", subjectdf, groups=subjectdf["subject"])
	fit = model.fit()
	report = fit.summary()

	# create a restriction for every regressor - except intercept (first) and random effects (last)
	omnibus_tests = np.eye(len(fit.params))[1:-1]
	anova = fit.f_test(omnibus_tests)

	names_for_plotting = {"ofM":u"na√Øve", "ofM_aF":"acute", "ofM_cF1":"chronic (2w)", "ofM_cF2":"chronic (4w)", "ofM_pF":"post"}
	voxeldf = voxeldf.replace({"session": names_for_plotting})
	subjectdf = subjectdf.replace({"session": names_for_plotting})
	if figure == "per-voxel":
		ax = sns.pointplot(x="session", y="t", hue="subject", data=voxeldf, ci=68.3, dodge=True, jitter=True, legend_out=False, units="subject")
		# sns.violinplot(x="session", y="value", hue="subject", data=df, inner=None)
		if xy_label:
			ax.set(xlabel=xy_label[0], ylabel=xy_label[1])
	elif figure == "per-participant":
		ax = sns.pointplot(x="session", y="t", data=subjectdf, ci=68.3, dodge=True, jitter=True, legend_out=False, units="subject", color=color)
		if xy_label:
			ax.set(xlabel=xy_label[0], ylabel=xy_label[1])
	elif figure == "both":
		f, (ax1, ax2) = plt.subplots(1,2)
		ax1 = sns.pointplot(x="session", y="t", hue="subject", data=voxeldf, ci=68.3, dodge=True, jitter=True, legend_out=False, units="subject", ax=ax1)
		ax2 = sns.pointplot(x="session", y="t", data=subjectdf, ci=68.3, dodge=True, jitter=True, legend_out=False, units="subject",ax=ax2, color=color)
		if xy_label:
			ax1.set(xlabel=xy_label[0], ylabel=xy_label[1])
			ax2.set(xlabel=xy_label[0], ylabel=xy_label[1])

	return fit, anova

def responders(l2_dir,
	roi="ctx_chr",
	data_root="~/NIdata/ofM.dr",
	roi_root="~/NIdata/templates/roi"
	):

	data_regex = "(?P<subject>.+)/tstat1.nii.gz"
	data_path = "{data_root}/l2/{l2_dir}/".format(data_root=data_root, l2_dir=l2_dir)
	data_path = os.path.expanduser(data_path)
	roi_path = "{roi_root}/{roi}.nii.gz".format(roi_root=roi_root, roi=roi)
	roi_path = os.path.expanduser(roi_path)

	data_find = DataFinder()
	data_find.inputs.root_paths = data_path
	data_find.inputs.match_regex = os.path.join(data_path,data_regex)
	found_data = data_find.run().outputs

	masker = NiftiMasker(mask_img=roi_path)
	voxeldf = pd.DataFrame({})
	for subject, data_file in zip(found_data.subject, found_data.out_paths):
		subject_data = {}
		print(subject, data_file)
		img = nib.load(data_file)
		img = masker.fit_transform(img)
		img = img.flatten()
		subject_data["subject"]=subject
		for i in img:
			voxel_data = deepcopy(subject_data)
			voxel_data["t"]=i
			df_ = pd.DataFrame(voxel_data, index=[None])
			voxeldf = pd.concat([voxeldf,df_])

def bids_substitution_iterator(sessions, subjects, scans, preprocessing_dir,
	l1_dir=None,
	l1_workdir=None,
	):
	"""A convenience layer to the SAMRI data structure"""
	if not l1_dir:
		l1_dir = preprocessing_dir
	if not l1_workdir:
		l1_workdir = l1_dir+"_work"
	substitutions=[]
	for subject, session, scan in product(subjects, sessions, scans):
		substitution={}
		substitution["subject"] = subject
		substitution["session"] = session
		substitution["scan"] = scan
		substitution["preprocessing_dir"] = preprocessing_dir
		substitution["l1_dir"] = l1_dir
		substitution["l1_workdir"] = l1_workdir
		substitutions.append(substitution)
	return substitutions

def p_filtering(substitution, ts_file_template, beta_file_template, p_file_template, design_file_template, p_level):
	ts_file = os.path.expanduser(ts_file_template.format(**substitution))
	beta_file = os.path.expanduser(beta_file_template.format(**substitution))
	p_file = os.path.expanduser(p_file_template.format(**substitution))
	design_file = os.path.expanduser(design_file_template.format(**substitution))
	try:
		img = nib.load(p_file)
	except (FileNotFoundError, nib.py3k.FileNotFoundError):
		return None,None,None,None
	data = img.get_data()
	header = img.header
	affine = img.affine
	shape = data.shape
	data = data.flatten()
	# print(np.count_nonzero(data))
	nonzeros = np.nonzero(data)
	_, nonzero_data, _, _ = multipletests(data[nonzeros], p_level, method="fdr_bh")
	nonzero_mask = deepcopy(nonzero_data)
	nonzero_mask[nonzero_data <= p_level] = 1
	nonzero_mask[nonzero_data > p_level] = 0
	data[nonzeros] = nonzero_mask
	data = data.reshape(shape)
	# print(np.count_nonzero(data))
	mask_map = nib.Nifti1Image(data, affine, header)
	p_masker = NiftiMasker(mask_img=mask_map)
	try:
		timecourse = p_masker.fit_transform(ts_file).T
		betas = p_masker.fit_transform(beta_file).T
	except ValueError:
		return None,None,None,None
	subplot_title = "\n ".join([str(substitution["subject"]),str(substitution["session"])])
	timecourse = np.mean(timecourse, axis=0)
	design = pd.read_csv(design_file, skiprows=5, sep="\t", header=None, index_col=False)
	design = design*np.mean(betas)
	return timecourse, design, mask_map, subplot_title

def roi_masking(substitution, ts_file_template, beta_file_template, design_file_template, roi_path):
	ts_file = os.path.expanduser(ts_file_template.format(**substitution))
	beta_file = os.path.expanduser(beta_file_template.format(**substitution))
	design_file = os.path.expanduser(design_file_template.format(**substitution))

	masker = NiftiMasker(mask_img=roi_path)
	mask_map = nib.load(roi_path)
	try:
		timecourse = masker.fit_transform(ts_file).T
		betas = masker.fit_transform(beta_file).T
	except ValueError:
		return None,None,None,None
	subplot_title = "\n ".join([str(substitution["subject"]),str(substitution["session"])])
	timecourse = np.mean(timecourse, axis=0)
	design = pd.read_csv(design_file, skiprows=5, sep="\t", header=None, index_col=False)
	design = design*np.mean(betas)
	return timecourse, design, mask_map, subplot_title

def roi_ts(substitutions,
	legend_loc="best",
	roi_path="~/NIdata/templates/roi/f_dr_chr.nii.gz",
	ts_file_template="~/NIdata/ofM.dr/preprocessing/{preprocessing_dir}/sub-{subject}/ses-{session}/func/sub-{subject}_ses-{session}_trial-{scan}.nii.gz",
	beta_file_template="~/NIdata/ofM.dr/l1/{l1_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_trial-{scan}_cope.nii.gz",
	design_file_template="~/NIdata/ofM.dr/l1/{l1_workdir}/_subject_session_scan_{subject}.{session}.{scan}/modelgen/run0.mat",
	):

	df = pd.DataFrame({})
	timecourses = []
	stat_maps = []
	subplot_titles = []
	designs = []
	roi_path = os.path.expanduser(roi_path)

	n_jobs = mp.cpu_count()-2
	substitutions_data = Parallel(n_jobs=n_jobs, verbose=0, backend="threading")(map(delayed(roi_masking),
		substitutions,
		[ts_file_template]*len(substitutions),
		[beta_file_template]*len(substitutions),
		[design_file_template]*len(substitutions),
		[roi_path]*len(substitutions),
		))
	timecourses, designs, stat_maps, subplot_titles = zip(*substitutions_data)

	timecourses = [x for x in timecourses if x is not None]
	designs = [x for x in designs if x is not None]
	stat_maps = [x for x in stat_maps if x is not None]
	subplot_titles = [x for x in subplot_titles if x is not None]

	return timecourses, designs, stat_maps, subplot_titles

def p_filtered_ts(substitutions,
	legend_loc="best",
	ts_file_template="~/NIdata/ofM.dr/preprocessing/{preprocessing_dir}/sub-{subject}/ses-{session}/func/sub-{subject}_ses-{session}_trial-{scan}.nii.gz",
	beta_file_template="~/NIdata/ofM.dr/l1/{l1_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_trial-{scan}_cope.nii.gz",
	p_file_template="~/NIdata/ofM.dr/l1/{l1_dir}/sub-{subject}/ses-{session}/sub-{subject}_ses-{session}_trial-{scan}_pstat.nii.gz",
	design_file_template="~/NIdata/ofM.dr/l1/{l1_workdir}/_subject_session_scan_{subject}.{session}.{scan}/modelgen/run0.mat",
	p_level=0.1,
	):

	df = pd.DataFrame({})
	timecourses = []
	stat_maps = []
	subplot_titles = []
	designs = []

	n_jobs = mp.cpu_count()-2
	substitutions_data = Parallel(n_jobs=n_jobs, verbose=0, backend="threading")(map(delayed(p_filtering),
		substitutions,
		[ts_file_template]*len(substitutions),
		[beta_file_template]*len(substitutions),
		[p_file_template]*len(substitutions),
		[design_file_template]*len(substitutions),
		[p_level]*len(substitutions),
		))
	timecourses, designs, stat_maps, subplot_titles = zip(*substitutions_data)

	timecourses = [x for x in timecourses if x is not None]
	designs = [x for x in designs if x is not None]
	stat_maps = [x for x in stat_maps if x is not None]
	subplot_titles = [x for x in subplot_titles if x is not None]

	return timecourses, designs, stat_maps, subplot_titles
